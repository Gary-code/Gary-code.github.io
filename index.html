<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">

    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
     strongsmall {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size:13px;
    font-weight: 700
    }
    smalll {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 13px;
    }
    stronghuge {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    huge {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 13px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 30px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="sjtu_icon.png">
  <title>Tan Wang</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link rel="shortcut icon" href="image/favicon.ico"/>
  <link rel="bookmark" href="image/favicon.ico"/>
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Tan Wang &nbsp;&nbsp;<font face="KaiTi" size="6">王谭</font></name>
        </p>
		<p>Tan Wang is a third-year undergraduate student in <a href="http://www.sice.uestc.edu.cn/">School of Information and Communication Engineering</a>, <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a>. His research interests include but not limit to Computer Vision, Visual Reasoning and Cross-modal Retreival. He is now a research assistant at <a href="http://cfm.uestc.edu.cn">Center for Future Media </a>, supervised by  Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. He also has a close research collaboration with Prof. <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan Hanjalic</a> at TU Delft.
         <p>Tan Wang is energetic in researching and interesting in daily life who loves running and trying new things. His advisor praises him as a <strong>self-motivated</strong> researcher with <strong>strong self-learning  ability</strong>. Please feel free to contact him if you have any interests or questions. 
        </p>


        <p align=center>
          <a href="mailto:wangt97@hotmail.com">Email</a> &nbsp/&nbsp
          <a href="image/cv_wangtan.pdf">CV</a> &nbsp/&nbsp
          <a href="https://github.com/Wangt-CN">Github</a> 

        </p>

        </td>
        <td width="33%">
        <img src="image/wangtan2.jpg" width="210">
        </td>
      </tr>
      </table>


<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading> &nbsp;<stronghuge>(Paper Accept or Reject, Recording my Progress...)</stronghuge>
          <p>
          <li> <strongsmall>[2019/04/09]</strongsmall> &nbsp;&nbsp;<smalll>1 revised paper (from CVPR19) summitted to  ACM MM19.</smalll><br/>
          <li> <strongsmall>[2019/03/23]</strongsmall> &nbsp;&nbsp;<smalll>1 paper with Prof. Alan Hanjalic submitted to ICCV19.</smalll><br/>
          <li> <strongsmall>[2019/02/25]</strongsmall>&nbsp;&nbsp; <smalll>CVPR boardline reject. Better than AAAI. Revise it and try again! </smalll><br/>
          <li> <strongsmall>[2018/12/24]</strongsmall> &nbsp;&nbsp;<smalll>1 revised paper (from AAAI19) submitted to TNNLS. </smalll><br/>
          <li> <strongsmall>[2018/11/13]</strongsmall> &nbsp;&nbsp;<smalll>1 new paper submitted to CVPR19. </smalll><br/>
          <li> <strongsmall>[2018/11/01]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper is regected by AAAI19 :(  Keep going! </smalll><br/>
          <li> <strongsmall>[2018/09/08]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper submitted to AAAI19.</smalll><br/>
          
          </p>
        </td>
      </tr>
</table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Education</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image/uestc_icon.jpg' width="100">
          </td>

          <td width="75%" valign="middle">
          <p>
          <stronghuge>University of Electronic Science and Technology of China (UESTC), China</stronghuge><br />
          Third-year undergraduate in Electronic Information Engineering &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016 - Present <br />
          GPA: <strong>93.57</strong>/100, &nbsp;&nbsp;Ranking: <strong>1/284</strong> (2018-2019) or <strong>1/415</strong> (first 2 years)<br />
          Advisors: Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>.  &nbsp;&nbsp; Collaborated with Prof. <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan Hanjalic</a>
          </p>
        </td>
      </tr>


        <tr>
          <td width="10%">
            <img src='image/chiba_icon.png' width="105">
          </td>

          <td width="90%" valign="middle">
          <p>
          <stronghuge>Chiba University, Japan</stronghuge><br />
          Exchange Program &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull;  Aug. 2017 <br />
          <a href="http://www.jst.go.jp/crcc/ssc/">Sakura Science Club Scholarship</a> awardee. Funded by Japan Science and Technology Agency <a href="http://www.jst.go.jp/EN/index.html">(JST)</a>.
          
          </p>
        </td>
      </tr>
      </table>

<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Honors & Scholarships</heading>
          <div style="line-height:25px">
          <p>
          <li> <stronghuge>National Scholarship</stronghuge> (Top 2% student),&nbsp; 2018<br/>
          <li> <stronghuge>National Scholarship</stronghuge> (Top 2% student),&nbsp; 2017<br/>
          <li>  <stronghuge>Tang Lixin Sponsored Elite Scholarship</stronghuge> (Only 60 awardees pre year in UESTC),&nbsp; 2017 <br/>
          <li> <stronghuge>Best Freshman Award</stronghuge> (Top 1 student per year in Department),&nbsp; 2016<br/>
          <li> <stronghuge>Honor Student Scholarship</stronghuge> (Top 10 students per year in Department),&nbsp; 2018<br/>
          <li> <stronghuge>Outstanding Student Scholarship</stronghuge> (Top 10% student),&nbsp; 2018<br/>
          <li> <stronghuge>Outstanding Student Scholarship</stronghuge> (Top 10% student),&nbsp; 2017<br/>
          </p>
          </div>
        </td>
      </tr>
</table>



<p></p><p></p><p></p><p></p><p></p>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research Experience</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image/cfm_icon4.png' width="100">
          </td>

          <td width="80%" valign="middle">
          <p>
          <stronghuge>Center For Future Media, UESTC</stronghuge><br />
          <huge><em>Research  Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Mar. 2018 - Present <br />
          Advisors: &nbsp; Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>.  &nbsp;&nbsp;Collaborated with  Prof. <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan Hanjalic</a><br/>
          <li> Proposed several novel methods for cross-modal retrieval which achieves the state-of-the-art performance on image-text matching.<br/>
          <li> Comnined the GCN with Visual Question Generation Task and further boost the performance on an unexplored challenging task zero-shot VQA. <br/>
          <li> Complete 3 works and make the submission.
          </p>
        </td>
      </tr>


<p></p>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication & Manuscript</heading>
        </td>
      </tr>
      </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image/CASC1.png'  width="200" height="130">
      </td>
      <td valign="top" width="75%">
      <!--
	  <a href="#">
            <papertitle>Cross-stream Selective Networks for Action Recognition</papertitle>
	  </a>
	  <br>
     -->
       
	  <a href="https://interxuxing.github.io/">Xing Xu*</a>,
      <strong>Tan Wang*</strong>,
	  <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
	  Lin Zuo,
      <a href="http://cfm.uestc.edu.cn/~fshen/">Fumin Shen</a>,
      <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
	      <em>Under Review</em>, TNNLS, 2018 <br>
          <em>Area: Visual and Language, Image-text matching</em> <br>
        <p></p>
        <p>In this paper, we propose a novel hybrid matching approach named Cross-modal Attention with Semantic Consistence (CASC) for image-text matching, which is a joint framework that performs cross-modal attention for local alignment and multi-label prediction for global semantic consistence.</p>
        <!-- <p . </p> -->
      </td>
    </tr>
   </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image/mtfn.png'  width="200" height="130">
      </td>
      <td valign="top" width="75%">
      <!--
    <a href="#">
            <papertitle>Cross-stream Selective Networks for Action Recognition</papertitle>
    </a>
    <br>
     -->
       <strong>Tan Wang</strong>,
    <a href="https://interxuxing.github.io/">Xing Xu</a>,
    <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
      <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan Hanjalic</a>,
      <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
        <em>Under Review</em>, ACM MM, 2019 <br>
          <em>Area: Visual and Language, Image-text matching</em> <br>
        <p></p>
        <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable matching performance with acceptable model complexity and much less time consuming. </p>
      </td>
    </tr>
   </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image/radial-gcn.png'  width="200" height="130">
      </td>
      <td valign="top" width="75%">
       <strong>Tan Wang</strong>,
    <a href="https://interxuxing.github.io/">Xing Xu</a>,
    <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
      <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan Hanjalic</a>,
      <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
        <em>Under Review</em>, ICCV, 2019 <br>
          <em>Area: Visual and Language, Visual Question Generation</em> <br>
        <p></p>
        <p>We propose an innovative answer-centric approach termed Radial Graph Convolutional Network (Radial-GCN) to focus on the relevant image regions only to reduce the complexity on VQG task.</p>
      </td>
    </tr>
   </table>




<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Leadership Experience</heading>
      </td>
      </tr>



      </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image/lecture.jpg'  width="195" height="130">
      </td>
      <td valign="top" width="75%">
        <stronghuge>Lecture Group of EE Department</stronghuge> </br>
        <huge><em>Founder & President</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Oct. 2017 - Sep. 2018 </br>
        <p></p>
        <p>
         <li> Organized academic forum, sharing sessions, Q&A meetings more than 30 times, serving over 1000 students on studying and future planing.<br/>
          <li> The team grows to 30 people and won the Outstanding Student Organisation prize in 2018.<br/>
          </p> 
      </td>
    </tr>
   </table>


       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="dachuang_stop()" onmouseover="dachuang_start()" >
      <td width="26%">
        <div class="one">
                <div class="two" id='dachuang_image'><img src='image/dachuang2.png'  width="195" height="130"></div>
                <img src='image/dachuang1.png'  width="195" height="130">
              </div>
      <script type="text/javascript">
                function dachuang_start() {
                  document.getElementById('dachuang_image').style.opacity = "1";
                }
                function dachuang_stop() {
                  document.getElementById('dachuang_image').style.opacity = "0";
                }
                dachuang_stop()
              </script>
      </td>

      <td valign="top" width="75%">
        <stronghuge>Innovative Entrepreneurship Project of UESTC</stronghuge> </br>
        <huge><em>Team Leader</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Sep. 2017 - Mar. 2018 </br>
        <p></p>
        <p>
         <li> This project focus on the pedestrian detection in low-light condition with excellent conclusion. We combine the recent pedestrian detection models with the low-light image enhancement algorithm based on Laplace operator.<br/>
         <li> Responsible for the code implementation and project promotion.<br/>
          </p> 
      </td>
    </tr>
   </table>
          




<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Personal Interests</heading>
          <p>
          <stronghuge>DOTA1</stronghuge>: My first and most playing PC game which accompanied me in my whole middle and high school. And I got about 1350 score  on the '11' Battle Platform Ladder Tournament. :)
          </p>
          <p>
          <stronghuge>Running</stronghuge>: During my college, I offen run a long distance for the pleasure releasing. And I have participated in the Chengdu Shuangyi Marathon in 2018.
          </p>
      </td>
      </tr>





   
   <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=250&t=tt&d=85Rlf3OqLYVhTE6hGEcHnAsDJl6O0EsUp326ZMpLzCI"></script>
   

     <!--  <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/9.js?i=5m6xs1j09rt&amp;t=bpan" async="async"></script> -->
  </body>
</html>
